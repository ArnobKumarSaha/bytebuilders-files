cnfRepSet:PRIMARY> sh.status()
--- Sharding Status --- 
  sharding version: {
  	"_id" : 1,
  	"minCompatibleVersion" : 5,
  	"currentVersion" : 6,
  	"clusterId" : ObjectId("65096d327f0d8714cc3b48e1")
  }
  shards:
        {  "_id" : "shard0",  "host" : "shard0/shard-shard0-0.shard-shard0-pods.demo.svc.cluster.local:27017,shard-shard0-1.shard-shard0-pods.demo.svc.cluster.local:27017",  "state" : 1,  "tags" : [ "shard0" ] }
  active mongoses:
        "4.4.6" : 2
  autosplit:
        Currently enabled: no
  balancer:
        Currently enabled:  no
        Currently running:  unknown
        Failed balancer rounds in last 5 attempts:  4
        Last reported error:  Could not find host matching read preference { mode: "primary" } for set shard0
        Time of Reported error:  Thu Sep 21 2023 03:50:11 GMT+0000 (UTC)
        Migration Results for the last 24 hours: 
                No recent migrations
  databases:
        {  "_id" : "config",  "primary" : "config",  "partitioned" : true }
                config.system.sessions
                        shard key: { "_id" : 1 }
                        unique: false
                        balancing: true
                        chunks:
                                shard0	1024
                        too many chunks to print, use verbose if you want to force print
        {  "_id" : "kubedb-system",  "primary" : "shard0",  "partitioned" : true,  "version" : {  "uuid" : UUID("070f09ce-0223-449f-8b02-6a7b88d158a4"),  "lastMod" : 1 } }
                kubedb-system.health-check
                        shard key: { "id" : 1 }
                        unique: false
                        balancing: true
                        chunks:
                                shard0	3
                        { "id" : { "$minKey" : 1 } } -->> { "id" : 0 } on : shard0 Timestamp(1, 1) 
                        { "id" : 0 } -->> { "id" : 1 } on : shard0 Timestamp(1, 2) 
                        { "id" : 1 } -->> { "id" : { "$maxKey" : 1 } } on : shard0 Timestamp(1, 3) 
                         tag: shard0  { "id" : 0 } -->> { "id" : 1 }



cnfRepSet:SECONDARY> sh.status()
--- Sharding Status --- 
  sharding version: {
  	"_id" : 1,
  	"minCompatibleVersion" : 5,
  	"currentVersion" : 6,
  	"clusterId" : ObjectId("65096d327f0d8714cc3b48e1")
  }
  shards:
        {  "_id" : "shard0",  "host" : "shard0/shard-shard0-0.shard-shard0-pods.demo.svc.cluster.local:27017,shard-shard0-1.shard-shard0-pods.demo.svc.cluster.local:27017",  "state" : 1,  "tags" : [ "shard0" ] }
  most recently active mongoses:
        "4.4.6" : 2
  autosplit:
        Currently enabled: no
  balancer:
        Currently enabled:  no
        Currently running:  unknown
        Failed balancer rounds in last 5 attempts:  4
        Last reported error:  Could not find host matching read preference { mode: "primary" } for set shard0
        Time of Reported error:  Thu Sep 21 2023 03:50:11 GMT+0000 (UTC)
        Migration Results for the last 24 hours: 
                No recent migrations
  databases:
        {  "_id" : "config",  "primary" : "config",  "partitioned" : true }
                config.system.sessions
                        shard key: { "_id" : 1 }
                        unique: false
                        balancing: true
                        chunks:
                                shard0	1024
                        too many chunks to print, use verbose if you want to force print
        {  "_id" : "kubedb-system",  "primary" : "shard0",  "partitioned" : true,  "version" : {  "uuid" : UUID("070f09ce-0223-449f-8b02-6a7b88d158a4"),  "lastMod" : 1 } }
                kubedb-system.health-check
                        shard key: { "id" : 1 }
                        unique: false
                        balancing: true
                        chunks:
                                shard0	3
                        { "id" : { "$minKey" : 1 } } -->> { "id" : 0 } on : shard0 Timestamp(1, 1) 
                        { "id" : 0 } -->> { "id" : 1 } on : shard0 Timestamp(1, 2) 
                        { "id" : 1 } -->> { "id" : { "$maxKey" : 1 } } on : shard0 Timestamp(1, 3) 
                         tag: shard0  { "id" : 0 } -->> { "id" : 1 }



mongos> sh.status()
--- Sharding Status --- 
  sharding version: {
  	"_id" : 1,
  	"minCompatibleVersion" : 5,
  	"currentVersion" : 6,
  	"clusterId" : ObjectId("65096d327f0d8714cc3b48e1")
  }
  shards:
        {  "_id" : "shard0",  "host" : "shard0/shard-shard0-0.shard-shard0-pods.demo.svc.cluster.local:27017,shard-shard0-1.shard-shard0-pods.demo.svc.cluster.local:27017",  "state" : 1,  "tags" : [ "shard0" ] }
  active mongoses:
        "4.4.6" : 2
  autosplit:
        Currently enabled: no
  balancer:
        Currently enabled:  no
        Currently running:  no
        Failed balancer rounds in last 5 attempts:  4
        Last reported error:  Could not find host matching read preference { mode: "primary" } for set shard0
        Time of Reported error:  Thu Sep 21 2023 03:50:11 GMT+0000 (UTC)
        Migration Results for the last 24 hours: 
                No recent migrations
  databases:
        {  "_id" : "config",  "primary" : "config",  "partitioned" : true }
                config.system.sessions
                        shard key: { "_id" : 1 }
                        unique: false
                        balancing: true
                        chunks:
                                shard0	1024
                        too many chunks to print, use verbose if you want to force print
        {  "_id" : "kubedb-system",  "primary" : "shard0",  "partitioned" : true,  "version" : {  "uuid" : UUID("070f09ce-0223-449f-8b02-6a7b88d158a4"),  "lastMod" : 1 } }
                kubedb-system.health-check
                        shard key: { "id" : 1 }
                        unique: false
                        balancing: true
                        chunks:
                                shard0	3
                        { "id" : { "$minKey" : 1 } } -->> { "id" : 0 } on : shard0 Timestamp(1, 1) 
                        { "id" : 0 } -->> { "id" : 1 } on : shard0 Timestamp(1, 2) 
                        { "id" : 1 } -->> { "id" : { "$maxKey" : 1 } } on : shard0 Timestamp(1, 3) 
                         tag: shard0  { "id" : 0 } -->> { "id" : 1 }
